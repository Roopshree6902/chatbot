import numpy as np
import nltk
import string
import random
f=open('chatking.txt','r',errors='ignore')
raw_doc=f.read()
raw_doc=raw_doc.lower()
nltk.download('punkt')
nltk.download('wordnet')
sent_tokens=nltk.sent_tokenize(raw_doc)
word_tokens=nltk.word_tokenize(raw_doc)

#NOW TEXT PRE PROCESSING
lemmer=nltk.stem.WordNetLemmatizer()
def LemTokens(tokens):
  return [lemmer.lemmatize(token) for token in tokens]
remove_punct_dict=dict((ord(punct), None) for punct in string.punctuation)
def LemNormalise(text):
  return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))

#Defining the greeting function
greet_inp=("hello","hi","yo","greetings","oi","oii","sup","what's up","hey")
greet_resp=["hi","hello","*nods*","hi there","hey","YOO! I am glad you are talking to me"]
def greet(sent):
  for word in sent.split():
    if word.lower() in greet_inp:
      return random.choice(greet_resp)

#response generation

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

def response(user_response):
  robo_resp=''
  TfidVec=TfidfVectorizer(tokenizer=LemNormalise, stop_words='english')
  tfidf=TfidVec.fit_transform(sent_tokens)
  vals=cosine_similarity(tfidf[-1], tfidf)
  idx=vals.argsort()[0][-2]
  flat=vals.flatten()
  flat.sort()
  req_tfidf=flat[-2]
  if(req_tfidf==0):
    robo_resp=robo_resp+"I am sorry!!!! I am not understanding you"
    return robo_resp
  else:
    robo_resp=robo_resp+sent_tokens[idx]
    return robo_resp

#Defining Conversation
flag=True
print("BOT:Hello my name is jangkilt.Let's have a conversation, also if you want to exit at any time just type Bye!!")
while(flag==True):
  user_response=input()
  user_response=user_response.lower()
  if(user_response!='bye'):
    if(user_response=='thanks' or user_response=='thank you'):
      flag=False
      print("BOT:You are welcome")
    else:
      if(greet(user_response)!=None):
        print("BOT: "+greet(user_response))
      else:
        sent_tokens.append(user_response)
        word_tokens=word_tokens+nltk.word_tokenize(user_response)
        final_words=list(set(word_tokens))
        print("BOT:",end="")
        print(response(user_response))
        sent_tokens.remove(user_response)
  else:
      flag=False
      print("BOT:Ok bye have a nice day .. :)")